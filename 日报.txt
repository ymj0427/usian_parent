2020.6.1日报
  ElasticSearch介绍
     什么是elasticsearch?
  	    elasticsearch是基于lucene的全文检索服务器，对外提供restful接口

     elasticsearch原理
  	    正排索引：查字典时从第一页开始找，直到找到关键字为止（CTRL+F）
  	    倒排索引：查字典时通过目录查找

  	 逻辑结构：一个倒排索引表，由三部分组成
  		document
  		term
  		term----关联----document
  安装：ElasticSearch、Kibana、head
     index管理：
        创建index
          PUT /java1906
            {
              "settings": {
                "number_of_shards": 2,
                "number_of_replicas": 0
              }
            }
        修改index
          PUT /java1906/_settings
            {
              "number_of_replicas" : 1
            }
        删除index
          DELETE /java1906 [, other_index]
     mapping管理
        创建mapping
          POST index_name/type_name/_mapping
        查询mapping
          GET /java1906/course/_mapping
     document管理
        创建document
            Post语法：POST/index_name/type_name{fieldname:fieldvalue}
            Put语法：PUT/index_name/type_name/id{field_name:field_value}
        查询document
            GET /index_name/type_name/id或
            GET /index_name/type_name/_search?q=field_name:field_value
        删除document
            语法：DELETE/index_name/type_name/id


2020.6.2日报
   IK分词器
      安装
    	解压到plugs目录下，并重命名为ik

      自定义词库
    	IkAnalyzer.cfg.xml：配置扩展词典和停用词典
    	main.dic：扩展词典
    	stopwords.dic：停用词典

      两种分词模式
    	ik_smart：粗粒度拆分
    	ik_max_word：细粒度拆分

   field详细介绍
      field的属性
    	type：field的类型
    	analyzer：分词模式、ik_smart、ik_max_word
    	index：创建doucument和分词列表
    	field索引不存储：
    		"_source":{
    			"excludes":{"description"}
    		}

      常用的field类型
    	文本字段：text

    	关键字字段：keyword 索引时不分词

    	日期字段：date

    	数字字段：long、integer、double、float

      field属性设置的标准
    			    标准
    		分词         是否有意义
    		索引         是否搜索
    		存储         是否展示
   springboot整合ES
     整合步骤
    	1、pom.xml
    		elasticsearch、elasticsearch-rest-high-level-client

    	2、application.yml
    		spring:
    		  data:
    		    elasticsearch:
    		      cluster-nodes: 192.168.233.134:9200
    	3、config
    		@Configuration
    		public class ElasticsearchConfig extends ElasticsearchProperties{

    			@Bean
    			public RestHighLevelClient getRestHighLevelClient() {
    			String[] hosts = getClusterNodes().split(",");
    			HttpHost[] httpHosts = new HttpHost[hosts.length];
    			for (int i = 0; i < httpHosts.length; i++) {
    			    String h = hosts[i];
    			    httpHosts[i] = new HttpHost(h.split(":")[0],
    							Integer.parseInt(h.split(":")[1]));
    			}
    				return new RestHighLevelClient(RestClient.builder(httpHosts));
    			}
    		}

     删除索引库
        DeleteIndexRequest deleteIndexRequest = new DeleteIndexRequest("java1906");
    	restHighLevelClient.indices().delete(deleteIndexRequest,RequestOptions.DEFAULT);
     创建索引库
    	CreateIndexRequest createIndexRequest = new CreateIndexRequest("java1906");
    	restHighLevelClient.indices().create(createIndexRequest,RequestOptions.DEFAULT)


2020.6.3日报
     添加文档
        IndexRequest indexRequest = new IndexRequest("java1906", "course", "1");
        restHighLevelClient.index(indexRequest,RequestOptions.DEFAULT);
     批量添加文档
        bulkRequest.add(new IndexRequest("java1906", "course","2").source("{\"name\":\"php实战\",\"description\":\"php谁都不服\",\"studymodel\":\"201001\",\"price\":\"5.6\"}", XContentType.JSON));
       	bulkRequest.add(new IndexRequest("java1906", "course","3").source("{\"name\":\"net实战\",\"description\":\"net从入门到放弃\",\"studymodel\":\"201001\",\"price\":\"7.6\"}", XContentType.JSON));
        restHighLevelClient.bulk(bulkRequest,RequestOptions.DEFAULT);
     修改文档
         UpdateRequest updateRequest = new UpdateRequest("java1906", "course", "1");
         restHighLevelClient.update(updateRequest,RequestOptions.DEFAULT);
     删除文档
         DeleteRequest deleteRequest = new DeleteRequest("java1906","course","1");
         restHighLevelClient.delete(deleteRequest,RequestOptions.DEFAULT);
     查询文档
        GetRequest getRequest = new GetRequest("java1906","course","1");
        restHighLevelClient.get(getRequest,RequestOptions.DEFAULT);
     DSL查询
        match_all查询
        	SearchRequest searchRequest = new SearchRequest("java1906");
        	searchRequest.types("course");
        	SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();
        	searchSourceBuilder.query(QueryBuilders.matchAllQuery());
        	searchRequest.search(searchSourceBuilder)
        	restHighLevelClient.search(searchRequest,RequestOptions.DEFAULT);
        分页查询
        	SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();
        	searchSourceBuilder.query(QueryBuilders.matchAllQuery());
        	searchSourceBuilder.form(1);
        	searchSourceBuilder.size(2);
        	searchSourceBuilder.sort("price",SortOrder.DESC);
        match查询
            SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();
            searchSourceBuilder.query(QueryBuilders.matchQuery("name", "spring开发").operator(Operator.AND));
            searchRequest.source(searchSourceBuilder);
            searchResponse = restHighLevelClient.search(searchRequest,RequestOptions.DEFAULT);
        multi_match查询
            SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();
            searchSourceBuilder.query(QueryBuilders.multiMatchQuery("开发","name","description"));
            searchRequest.source(searchSourceBuilder);
            searchResponse = restHighLevelClient.search(searchRequest,RequestOptions.DEFAULT);
        bool查询
            SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();
            BoolQueryBuilder boolQueryBuilder = QueryBuilders.boolQuery();
            boolQueryBuilder.must(QueryBuilders.matchQuery("name", "开发"));
            boolQueryBuilder.must(QueryBuilders.matchQuery("description","开发"));
            searchSourceBuilder.query(boolQueryBuilder);
            searchRequest.source(searchSourceBuilder);
            searchResponse = restHighLevelClient.search(searchRequest,RequestOptions.DEFAULT);
        filter查询
            SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();
            BoolQueryBuilder boolQueryBuilder = QueryBuilders.boolQuery();
            boolQueryBuilder.must(QueryBuilders.matchQuery("name","开发"));
            boolQueryBuilder.filter(QueryBuilders.rangeQuery("price").gte(10).lte(100))
            searchSourceBuilder.query(boolQueryBuilder);
            searchRequest.source(searchSourceBuilder);
            searchResponse = restHighLevelClient.search(searchRequest,RequestOptions.DEFAULT);

2020.6.4日报
1、搭建ES集群
2、搜索展示的商品信息，将信息存入ES中

2020.6.5日报
    商品搜索
    usian_search_service
         SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();
         HighlightBuilder highlightBuilder = new HighlightBuilder();
                    highlightBuilder.preTags("<font color='red'>");
                    highlightBuilder.postTags("</font>");
                    highlightBuilder.field("item_title");
                    searchSourceBuilder.highlighter(highlightBuilder);
    新增商品同步索引库
        common_mapper
            SearchItemMapper：SearchItem getItemById(Long itemId);
            SearchItemMapper.xml：
                        a.id,
                		a.title item_title,
                		a.sell_point item_sell_point,
                		a.price item_price,
                		a.image item_image,
                		b.name item_category_name,
                		c.item_desc item_desc
                	FROM
                		tb_item a
                	JOIN tb_item_cat b ON a.cid = b.id
                	JOIN tb_item_desc c ON a.id = c.item_id
                	WHERE a.status = 1
                	  AND a.id=#{itemId}
        usian_search_service
            pom：spring-boot-starter-amqp
            application.yml：
                spring:
                  rabbitmq:
                    host: 192.168.29.134
                    username: admin
                    password: 1111
                    virtual-host: /
            service：
                SearchItem searchItem = searchItemMapper.getItemById(Long.valueOf(itemId));
                IndexResponse indexResponse = restHighLevelClient.index(indexRequest,RequestOptions.DEFAULT);
            listerner：
                value = @Queue(value="search_queue",durable = "true"),
                exchange = @Exchange(value="item_exchage",type= ExchangeTypes.TOPIC),
                key= {"item.*"}
        usian_item_service
            pom.xml：spring-boot-starter-amqp
            application.yml：
                spring:
                  rabbitmq:
                    host: 192.168.233.132
                    username: admin
                    password: 1111
                    virtual-host: /

2020.6.8日报
    商品搜索
       方案一：thymeleaf页面静态化
             a、创建商品详情的thymeleaf模板
             b、创建RabbitMQ消费者，收到消息后生成静态页面（D:/detail/26774635180.html）
             c、搭建nginx服务器，返回静态页面

       方案二：redis
             a、redis缓存商品详情
                 1、先查询redis，如果有直接返回
                 2、再查询mysql，并把查询结果装到redis中再返回

             b、如何保证redis不满？redis中都是热点商品？
                设置商品的实现时间：86400

             c、怎么保存商品信息（数据类型）？
                ITEM_INFO:123456:BASE
                ITEM_INFO:123456:DESC
                ITEM_INFO:123456:PARAM
    缓存穿透
        概述：
            当用户很发起很多请求的时候，缓存都没有命中，于是都去请求了持久层数据库，这会给持久层数据库造成很大的压力。
        解决方案：
            当存储层不命中后，即使返回的空对象也将其缓存起来，同时会设置一个过期时间（避免控制占用更多的存储空间），之后再访问这个数据将会从缓存中获取，保护了后端数据源
    缓存击穿
        概述：
            缓存击穿，是指一个key非常热点，在不停的扛着大并发，大并发集中对这一个key不停进行访问，当这个key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库，就像在一个屏障上凿开了一个洞。
        解决方案：
            1、设置热点数据永远不过期
            2、加分布式锁

2020.6.9日报
    1、注册信息校验
        /**
         * 对用户的注册信息(用户名与电话号码)做数据校验
         */
        @Override
        public boolean checkUserInfo(String checkValue, Integer checkFlag) {
            TbUserExample example = new TbUserExample();
            TbUserExample.Criteria criteria = example.createCriteria();
            // 1、查询条件根据参数动态生成：1、2分别代表username、phone
            if (checkFlag == 1) {
                criteria.andUsernameEqualTo(checkValue);
            } else if (checkFlag == 2) {
                criteria.andPhoneEqualTo(checkValue);
            }
            // 2、从tb_user表中查询数据
            List<TbUser> list = tbUserMapper.selectByExample(example);
            // 3、判断查询结果，如果查询到数据返回false。
            if (list == null || list.size() == 0) {
                // 4、如果没有返回true。
                return true;
            }
            // 5、如果有返回false。
            return false;
        }
    }
    2、用户注册
         /**
         * 用户注册
         */
        @Override
        public Integer userRegister(TbUser user) {
            //将密码做加密处理。
            String pwd = MD5Utils.digest(user.getPassword());
            user.setPassword(pwd);
            //补齐数据
            user.setCreated(new Date());
            user.setUpdated(new Date());
            return this.tbUserMapper.insert(user);
        }
    3、用户登录
        @Override
        public Map userLogin(String username, String password) {
            // 1、判断用户名密码是否正确。
            String pwd = MD5Utils.digest(password);
            TbUserExample example = new TbUserExample();
            TbUserExample.Criteria criteria = example.createCriteria();
            criteria.andUsernameEqualTo(username);
            criteria.andPasswordEqualTo(pwd);
            List<TbUser> userList = this.tbUserMapper.selectByExample(example);
            if(userList == null || userList.size() <= 0){
                return null;
            }
            TbUser tbUser = userList.get(0);
            // 2、登录成功后生成token。Token相当于原来的jsessionid，字符串，可以使用uuid。
            String token = UUID.randomUUID().toString();
            // 3、把用户信息保存到redis。Key就是token，value就是TbUser对象转换成json。
            tbUser.setPassword(null);
            redisClient.set(USER_INFO + ":" + token, tbUser);
            // 5、设置key的过期时间。模拟Session的过期时间。
            redisClient.expire(USER_INFO + ":" + token, SESSION_EXPIRE);

            Map<String,String> map = new HashMap<String,String>();
            map.put("token",token);
            map.put("userid",tbUser.getId().toString());
            map.put("username",tbUser.getUsername());
            return map;
        }
    4、通过token查询用户信息
        1、从url中取参数token
        2、根据token查询redis
        3、如果查询不到数据，前台删除cookie中的用户信息
        4、如果查询到数据，说明用户已经登录需要重置key的过期时间

         /**
         * 查询用户登录是否过期
         * @param token
         * @return
         */
        @Override
        public TbUser getUserByToken(String token) {
            TbUser tbUser = (TbUser) redisClient.get(USER_INFO + ":" + token);
            if(tbUser!=null){
                //需要重置key的过期时间。
                redisClient.expire(USER_INFO+":"+token,SESSION_EXPIRE);
                return tbUser;
            }
            return null;
        }

    5、退出登录
        /**
         * 用户退出登录
         * @param token
         */
        @Override
        public Boolean logOut(String token) {
           return redisClient.del(USER_INFO + ":" + token);
        }

2020.6.10日报
    购物车
        添加购物车商品
        展示购物车列表页面
        修改购物车商品数量
        删除购物车商品
    未登录状态下：
        从cookie中查询商品列表Map<itemId,TbItem> 商品购买数量使用TbItem的num保存
        ​	购物车已存在则直接返回
        ​   购物车不存在则创建空的购物车并返回
        添加商品到购物车：
        ​	如果购物车存在该商品，商品数量相加。
        ​	如果购物车不存在该商品，根据商品id查询商品信息并添加到购车列表
        把购车商品列表写入cookie。
        ​	读写cookie可以使用CookieUtils工具类实现

    登录状态下：
        使用redis存储商品列表，使用hash对购物车进行归类
        从redis中查询商品列表
        将商品添加大购物车中
        将购物车缓存到redis中


2020.6.16日报
    订单功能：
        身份认证功能：
               使用springmvc的拦截器拦截所有订单的请求
               2、业务逻辑
                    a)  从cookie中取token。
                    b) 根据token调用sso服务查询用户信息。
                    d) 如果查不到用户信息则跳转到登录页面。
                    e) 查询到用户信息放行。
               代码：
                    在结算之前判断用户是否登录
                    @Component
                    public class UserLoginInterceptor implements HandlerInterceptor {

                        @Autowired
                        private SSOServiceFeign ssoServiceFeign;

                        @Override
                        public boolean preHandle(HttpServletRequest request, HttpServletResponse
                                response, Object handler) throws Exception {
                            //对用户的 token 做判断
                            String token = request.getParameter("token");
                            if (StringUtils.isBlank(token)) {
                                return false;
                            }
                            //如果用户 token 不为空，则校验用户在 redis 中是否失效
                            TbUser tbUser = ssoServiceFeign.getUserByToken(token);
                            if (tbUser == null) {
                                return false;
                            }
                            return true;
                        }
                    }

                    /**
                     * 拦截器配置类
                     */
                    @Configuration
                    public class WebConfig implements WebMvcConfigurer {
                        @Autowired
                        private UserLoginInterceptor userLoginInterceptor;

                        /**
                         * 注册拦截器
                         * @param registry
                         */
                        @Override
                        public void addInterceptors(InterceptorRegistry registry) {
                            InterceptorRegistration registration =
                                    registry.addInterceptor(this.userLoginInterceptor);
                            //拦截那个 URI
                            registration.addPathPatterns("/frontend/order/**");
                        }
                    }

         展示订单确认页面：
                1、在购物车页面点击“去结算”按钮跳转到订单确认页面。
                2、请求的url：/frontend/order/goSettlement
                3、参数：ids，userId
                4、查询redis中的购物车数据并返回给前端
                5、配送地址列表，需要用户登录。需要根据用户id查询收货地址列表。静态数据。
                6、支付方式。静态数据。

                /**
                 * 订单服务 Controller
                 */
                @RestController
                @RequestMapping("/frontend/order")
                public class OrderController {

                    @Autowired
                    private CartServiceFeign cartServiceFeign;

                    @Autowired
                    private OrderServiceFeign orderServiceFeign;

                    @RequestMapping("/goSettlement")
                    public Result goSettlement(String[] ids, String userId) {
                        //获取购物车
                        Map<String, TbItem> cart = cartServiceFeign.selectCartByUserId(userId);
                        //从购物车中获取选中的商品
                        List<TbItem> list = new ArrayList<TbItem>();
                        for (String id : ids) {
                            list.add(cart.get(id));
                        }
                        if(list.size()>0) {
                            return Result.ok(list);
                        }
                        return Result.error("error");
                    }
                }

2020.6.17日报
    提交订单:
        生成订单号：时间戳+用户id +店铺id
        保存订单信息
            a、在订单确认页面点击“提交订单”按钮生成订单。
            b、请求的url：/frontend/order/insertOrder
            c、参数：订单、订单商品、订单物流
            d、返回值：{"status":200,"msg":"OK","data":"订单ID"}

            @Override
            public String insertOrder(OrderInfo orderInfo) {
                //1、解析orderInfo
                TbOrder tbOrder = orderInfo.getTbOrder();
                TbOrderShipping tbOrderShipping = orderInfo.getTbOrderShipping();
                List<TbOrderItem> tbOrderItemList =
                    JsonUtils.jsonToList(orderInfo.getOrderItem(), TbOrderItem.class);

                //2、保存订单信息
                if(!redisClient.exists(ORDER_ID_KEY)){
                    redisClient.set(ORDER_ID_KEY,ORDER_ID_BEGIN);
                }
                Long orderId = redisClient.incr(ORDER_ID_KEY, 1L);
                tbOrder.setOrderId(orderId.toString());
                Date date = new Date();
                tbOrder.setCreateTime(date);
                tbOrder.setUpdateTime(date);
                //1、未付款，2、已付款，3、未发货，4、已发货，5、交易成功，6、交易关闭
                tbOrder.setStatus(1);
                tbOrderMapper.insertSelective(tbOrder);

                //3、保存明细信息
                if(!redisClient.exists(ORDER_ITEM_ID_KEY)){
                    redisClient.set(ORDER_ITEM_ID_KEY,0);
                }
                for (int i = 0; i < tbOrderItemList.size(); i++) {
                    Long oderItemId = redisClient.incr(ORDER_ITEM_ID_KEY, 1L);
                    TbOrderItem tbOrderItem =  tbOrderItemList.get(i);
                    tbOrderItem.setId(oderItemId.toString());
                    tbOrderItem.setOrderId(orderId.toString());
                    tbOrderItemMapper.insertSelective(tbOrderItem);
                }

                //4、保存物流信息
                tbOrderShipping.setOrderId(orderId.toString());
                tbOrderShipping.setCreated(date);
                tbOrderShipping.setUpdated(date);
                tbOrderShippingMapper.insertSelective(tbOrderShipping);

                //5、返回订单id
                return orderId.toString();
            }
        }

    扣减库存：
        将消息写入消息队列，业务逻辑以异步的方式运行，加快响应速度
            usian_order_service
                service
                    @Service
                    @Transactional
                    public class OrderServiceImpl implements OrderService {
                        ... ... ...
                        @Autowired
                        private AmqpTemplate amqpTemplate;

                        @Override
                        public Long insertOrder(OrderInfo orderInfo) {
                            /************1、向订单表插入数据。********/
                            ... ... ...
                            /************2、向订单明细表插入数据********/
                            ... ... ...
                            /************3、向订单物流表插入数据。********/
                            ... ... ...

                            //发布消息到mq，完成扣减库存
                            amqpTemplate.convertAndSend("order_exchage","order.add", orderId);

                            /************4、返回订单id********/
                            ... ... ...
                        }
                    }
            usian_item_service
                service
                    /**
                    	 * 修改商品库存数量
                    	 * @param orderId
                    	 * @return
                    	 */
                        @Override
                        public Integer updateTbItemByOrderId(String orderId) {
                            TbOrderItemExample tbOrderItemExample = new TbOrderItemExample();
                            TbOrderItemExample.Criteria criteria = tbOrderItemExample.createCriteria();
                            criteria.andOrderIdEqualTo(orderId);
                            List<TbOrderItem> tbOrderItemList =
                                	tbOrderItemMapper.selectByExample(tbOrderItemExample);
                            int result = 0;
                            for (int i = 0; i < tbOrderItemList.size(); i++) {
                                TbOrderItem tbOrderItem =  tbOrderItemList.get(i);
                                TbItem tbItem =
                                    tbItemMapper.selectByPrimaryKey(Long.valueOf(tbOrderItem.getItemId()));
                                tbItem.setNum(tbItem.getNum()-tbOrderItem.getNum());
                                result += tbItemMapper.updateByPrimaryKeySelective(tbItem);
                            }
                            return result;
                        }
                listener
                    /**
                         * 监听者接收消息三要素：
                         *  1、queue
                         *  2、exchange
                         *  3、routing key
                         */
                        @RabbitListener(bindings = @QueueBinding(
                            value = @Queue(value="item_queue",durable = "true"),
                            exchange = @Exchange(value="order_exchage",type= ExchangeTypes.TOPIC),
                            key= {"*.*"}
                        ))
                        public void listen(String orderId) throws Exception {
                            System.out.println("接收到消息：" + orderId);
                            Integer result = itemService.updateTbItemByOrderId(orderId);
                            if(!(result>0)){
                                throw new RuntimeException("扣减失败");
                            }
                        }
                    }

2020.6.18日报
    关闭超时的订单：
       <!-- quartz启动器 -->
       <dependency>
           <groupId>org.springframework.boot</groupId>
           <artifactId>spring-boot-starter-quartz</artifactId>
       </dependency>

        QuartzConfig
           /**
             * 1.创建Job对象
             */
            @Bean
            public JobDetailFactoryBean jobDetailFactoryBean(){
                JobDetailFactoryBean factory = new JobDetailFactoryBean();
                //关联我们自己的Job类
                factory.setJobClass(OrderQuartz.class);
                return factory;
            }

            /**
             * Cron Trigger
             */
              @Bean
            public CronTriggerFactoryBean cronTriggerFactoryBean(JobDetailFactoryBean
                                                                    jobDetailFactoryBean){
                CronTriggerFactoryBean factory = new CronTriggerFactoryBean();
                factory.setJobDetail(jobDetailFactoryBean.getObject());
                //设置触发时间
                //factory.setCronExpression("0/2 * * * * ?");
                factory.setCronExpression("0 */1 * * * ?");
                return factory;
            }

            /**
             * 3.创建Scheduler对象
             */
            @Bean
            public SchedulerFactoryBean schedulerFactoryBean(CronTriggerFactoryBean
                            cronTriggerFactoryBean, MyAdaptableJobFactory myAdaptableJobFactory){
                SchedulerFactoryBean factory = new SchedulerFactoryBean();
                //关联trigger
                factory.setTriggers(cronTriggerFactoryBean.getObject());
                factory.setJobFactory(myAdaptableJobFactory);
                return factory;
            }

        MyAdaptableJobFactory
            //AutowireCapableBeanFactory 可以将一个对象添加到SpringIOC容器中，并且完成该对象注入
            	@Autowired
            	private AutowireCapableBeanFactory autowireCapableBeanFactory;

            	/**
            	 * 解决任务类中注入service报错问题：
            	 * 	该方法将需要实例化的任务对象手动的添加到springIOC容器中并且完成对象的注入
            	 */
            	@Override
            	protected Object createJobInstance(TriggerFiredBundle bundle) throws Exception {
            		Object obj = super.createJobInstance(bundle);
            		//将obj对象添加Spring IOC容器中，并完成注入
            		this.autowireCapableBeanFactory.autowireBean(obj);
            		return obj;
            	}
        OrderQuartz
            @Autowired
            	private OrderService orderService;

            	/**
            	 * 关闭超时订单
            	 */
            	@Override
                public void execute(JobExecutionContext context) throws JobExecutionException {
                    //1、查询超时订单
                     List<TbOrder> tbOrderList = orderService.selectOverTimeTbOrder();

                    //2、关闭超时订单
                    for (int i = 0; i < tbOrderList.size(); i++) {
                        TbOrder tbOrder =  tbOrderList.get(i);
                        orderService.updateOverTimeTbOrder(tbOrder);

                        //3、把超时订单中的商品库存数量加回去
                        orderService.updateTbItemByOrderId(tbOrder.getOrderId());
                    }
                }
        service
            /**
                 * 查询超时订单
                 * @return
                 */
                @Override
                public List<TbOrder> selectOvertimeOrder() {
                    return orderMapper.selectOvertimeOrder();
                }

                /**
                 * 关闭超时订单
                 * @param tbOrder
                 */
                @Override
                public void updateOverTimeTbOrder(TbOrder tbOrder) {
                    tbOrder.setStatus(6);
                    Date date = new Date();
                    tbOrder.setCloseTime(date);
                    tbOrder.setEndTime(date);
                    tbOrder.setUpdateTime(date);
                    tbOrderMapper.updateByPrimaryKeySelective(tbOrder);
                }

                /**
                 * 把订单中商品的库存数量加回去
                 * @param itemId
                 * @param num
                 */
                @Override
                   @Override
                public void updateTbItemByOrderId(String orderId) {
                    //1、通过orderId查询LisT<TbOrderItem>
                    TbOrderItemExample tbOrderItemExample = new TbOrderItemExample();
                    TbOrderItemExample.Criteria criteria = tbOrderItemExample.createCriteria();
                    criteria.andOrderIdEqualTo(orderId);
                    List<TbOrderItem> tbOrderItemList =
                        tbOrderItemMapper.selectByExample(tbOrderItemExample);
                    for (int i = 0; i < tbOrderItemList.size(); i++) {
                        TbOrderItem tbOrderItem =  tbOrderItemList.get(i);
                        //2、修改商品库存
                        TbItem tbItem =
                            tbItemMapper.selectByPrimaryKey(Long.valueOf(tbOrderItem.getItemId()));
                        tbItem.setNum(tbItem.getNum()+tbOrderItem.getNum());
                        tbItem.setUpdated(new Date());
                        tbItemMapper.updateByPrimaryKey(tbItem);
                    }
                }
    quartz集群任务重复执行问题：
        quartz
            @Autowired
            	private OrderService orderService;

            	@Autowired
            	private RedisClient redisClient;

            	/**
            	 * 关闭超时订单
            	 */
            	@Override
            	public void execute(JobExecutionContext context) throws JobExecutionException {
            		String ip = null;
            		try {
            			ip = InetAddress.getLocalHost().getHostAddress();
            		} catch (UnknownHostException e) {
            			e.printStackTrace();
            		}
            		//解决quartz集群任务重复执行
            		if(redisClient.setnx("SETNX_LOCK_ORDER_KEY",ip,30)) {
            			//... ... ... 关闭超时订单业务
            			redisClient.del("SETNX_LOCK_ORDER_KEY");
            		}else{
            			System.out.println(
                            "============机器："+ip+" 占用分布式锁，任务正在执行=======================");
            		}
                }
            }

2020.6.19日报
    事务的介绍:
        当你需要一次执行多条SQL语句时，可以使用事务。通俗一点说，如果这几条SQL语句全部执行成功，则才对数据库进行一次更新，
        如果有一条SQL语句执行失败，则这几条SQL语句全部不进行执行，这个时候需要用到事务。

        本地事务：
            在计算机系统中，更多的是通过关系型数据库来控制事务，这是利用数据库本身的事务特性来实现的，因此叫数据库事务，
            由于应用主要靠关系数据库来控制事务，而数据库通常和应用在同一个服务器，所以基于关系型数据库的事务又被称为本地事务。

        jdbc中使用事物：
             1.获取对数据库的连接
             2.设置事务不自动提交（默认情况是自动提交的）
    分布式事务：
        分布式系统会把一个应用系统拆分为可独立部署的多个服务，因此需要服务与服务之间远程协作才能完成事务操作，
        这种分布式系统环境下由不同的服务之间通过网络远程协作完成事务称之为分布式事务，例如用户注册送积分事务、
        创建订单减库存事务，银行转账事务等都是分布式事务。

    分布式事物产生的场景：
        1、典型的场景就是微服务架构 微服务之间通过远程调用完成事务操作。 比如：订单微服务和库存微服务，
            下单的同时订单微服务请求库存微服务减库存。简言之：跨JVM进程产生分布式事务。

        2、单体系统访问多个数据库实例 当单体系统需要访问多个数据库（实例）时就会产生分布式事务。
                比如：用户信息和订单信息分别在两个MySQL实例存储，用户管理系统删除用户信息，
                需要分别删除用户信息及用户的订单信息，由于数据分布在不同的数据实例，需要通过不同的数据库链接去操作数据，
                此时产生分布式事务。 简言之：跨数据库实例产生分布式事务。

        3、多服务访问同一个数据库实例 比如：订单微服务和库存微服务即使访问同一个数据库也会产生分布式事务，
           两个微服务持有了不同的数据库链接进行数据库操作，此时产生分布式事务。简言之：跨JVM进程产生分布式事务。

    RabbitMQ可靠消息最终一致性介绍：
        在实际系统的开发过程中，可能服务间的调用是异步的。也就是说，一个服务发送一个消息给 MQ，
        即消息中间件，比如RocketMQ、RabbitMQ、Kafka、ActiveMQ 等等。然后，另外一个服务从 MQ 消费到一条消息后进行处理。这就成了基于 MQ 的异步调用了。

        那么针对这种基于 MQ 的异步调用，如何保证各个服务间的分布式事务呢？也就是说，我希望的是基于MQ 实现异步调用的多个服务的业务逻辑，
        要么一起成功，要么一起失败。这个时候，就要用上可靠消息最终一致性方案，来实现分布式事务。

    什么是可靠消息最终一致性：
        在实际系统的开发过程中，可能服务间的调用是异步的。也就是说，一个服务发送一个消息给 MQ，即消息中间件，比如RocketMQ、RabbitMQ、Kafka、ActiveMQ 等等。

        然后，另外一个服务从 MQ 消费到一条消息后进行处理。这就成了基于 MQ 的异步调用了。

        那么针对这种基于 MQ 的异步调用，如何保证各个服务间的分布式事务呢？也就是说，我希望的是基于MQ 实现异步调用的多个服务的业务逻辑，
        要么一起成功，要么一起失败。这个时候，就要用上可靠消息最终一致性方案，来实现分布式事务。

    可靠消息最终一致性要解决的问题：
        上游服务把信息成功发送：
            本地事务与消息发送的原子性问题：事务发起方在本地事务执行成功后消息必须发出去，否则就回滚事务。即实现本地事务和消息发送的原子性，要么都成功，要么都失败。

        下游服务成把消息成功消费：
            事务参与方接收消息的可靠性：事务参与方必须能够从消息队列接收到消息。

        对消息做幂：
            消息重复消费的问题：由于网络2的存在，若某一个消费节点响应超时但是消费成功，此时消息中间件会重复投递此消息，就导致了消息的重复消费。

        问题一：上游服务把消息成功发送：
            针对问题一可采用消息表这个方案，该方案最初是eBay提出的，此方案的核心是：在系统A处理任务完成后，
            在本地记录待发送信息。一个定时任务不断检查，是否发送成功，如果发送成功，将记录状态修改。
        问题二：下游服务成把消息成功消费：
            消息重试：消息持久化后，如果消息在投递过程中丢失，或消息的确认应答在返回途中丢失，那么消息中间件就会重新投递，直到下游消费者返回消费成功响应为止。
            任务失败：当任务处理失败后，则返回给消息中间件失败，消息会重复发送
        问题三：对消息做幂等：
            任务B处理消息前，先查询该消息是否被消费，如果没消费，处理任务B成功，记录消息。如果消息已经被消费，直接返回应答成功

2020.6.22日报
    ItemMQListener
         public void listener(String msg, Channel channel, Message message)
                														throws IOException {
                LocalMessage localMessage = JsonUtils.jsonToPojo(msg, LocalMessage.class);

                //进行幂等判断，防止ack应为网络问题没有送达，导致扣减库存业务重复执行
                DeDuplication deDuplication =
                    deDuplicationService.selectDeDuplicationByTxNo(localMessage.getTxNo());
                if(deDuplication==null){
                    //扣减库存
                    Integer result =
                        itemService.updateTbItemByOrderId(localMessage.getOrderNo());
                    if(!(result>0)){
                        throw new RuntimeException("扣减库存失败");
                    }
                    //记录成功执行过的事务
                    deDuplicationService.insertDeDuplication(localMessage.getTxNo());
                }else{
                    System.out.println("=======幂等生效：事务"+deDuplication.getTxNo()
                            +" 已成功执行===========");
                }
                channel.basicAck(message.getMessageProperties().getDeliveryTag(),false);
            }
    分布式日志:
        ELK介绍:
               ELK是Elasticsearch、Logstash、Kibana的简称（也称为 ELK Stack），是elastic公司提供的一套完整的日志收集以及展示的解决方案，
            能够安全可靠地获取任何来源、任何格式的数据，然后实时地对数据进行搜索、分析和可视化。

            - Elasticsearch：是开源的分布式全文检索服务器。
            - Logstash：是一个具有实时传输能力的数据收集引擎，用来进行数据收集（如：读取文本文件）、解析，并将数据发送给ES。
            - Kibana：数据分析与可视化平台，对Elasticsearch存储的数据进行可视化分析，通过表格的形式展现出来。

        为什么要用 ELK？
            一般大型系统都采用分布式架构，不同的模块部署在不同的服务器上，大规模分布式项目的日志面临的问题如下：
            1. 文本搜索太慢怎么办？
            2. 分布式环境下的日志如何查询？
            3. 如何多维度查询？

2020.6.24日报
	一、mysql主从复制（安装mysql）
 		linux安装mysql
		查看已安装mysql：rpm -qa|grep mysql
		卸载：rpm -e --nodeps mysql-libs-5.1.7.1-1.e16.x86_64
		解压安装包到指定文件夹：tar -zxvf mysql-5.6.31-linux-glibc2.5-x86_64.tar.gz -C /usr/java
		进入/usr/java：cd /usr/java
		改名mysql：mv mysql-5.6.31-linux-glibc2.5-x86_64 mysql
		复制mysql配置文件：cd mysql
				cp support-files/my-default.cnf /etc/my.cnf
				cp support-files/mysql.server /etc/rc.d/init.d/mysql
		修改my.cnf  vim /etc/my.cnf
		          	basedir = /usr/java/mysql
			datadir = /usr/java/mysql/data
			log-error = /usr/java/mysql/data/error.log
			pid-file = /usr/java/mysql/data/mysql.pid
			user = root
			tmpdir = /tmp
		初始化mysql：./scripts/mysql_install_db --user=root --basedir=/usr/java/mysql --datadir=/usr/java/mysql/data --pid-file=/usr/java/mysql/data/mysql.pid --tmpdir=/tmp
		启动mysql：service mysql start
		关闭mysql：service mysql stop
		重启mydql：service mysql restart
		修改MySQL密码：mysql -u root
			            use mysql
			            update user set password= password("1111") where user='root';
			            flush privileges;
		开放远程登陆权限：GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY '1111' WITH GRANT OPTION;
 				FLUSH PRIVILEGES;
	二、mysql主从复制（配置）
		主从复制简介
		1. MySQL 默认支持主(master)从(slave)功能.
		2. 主从复制效果：在主数据库中操作时,从同步进行变化.
		3. 主从复制本质：主数据的操作写入到日志中,从数据库从日志中读取,进行操作.
		主从复制要素
		1. 开启日志功能
   		2. 每个数据库需要有一个 server_id,主 server_id 值小于从server_id(标识从哪server写入的)
   		3. 每个 mysql 都有一个 uuid,由于虚拟机直接进行克隆,需要修改uuid 的值(唯一识别码)
   		4. 必须要在主数据库中有一个用户具有被从数据库操作的权限.
		配置主从复制
		配置主数据库
		1.修改主数据库my.cnf
		  log_bin=master_log
		  server_id=1
		2.重启mysql：service mysql restart
		3.通过命令可以观察主数据库在主从关系中状态: show master status
		配置从数据库
		1.修改server_id: server_id=2
		2.data文件夹auto.cnf编写当前mysql的uuid
		3.重启 mysql servIce：service mysql restart
		4.修改slave：
		 stop slave;
		change master to master_host='主ip',master_user='root',master_password='1111',master_log_file='master_log.000001';
		start slave
		5.查看slave状态：首位slavestatus \G;
		6.验证主从关系：在主数据库中新建数据库,新建表,添加数据,观察从数据库的
	二、mycat
		1、什么是Mycat：是一个国产的数据库中间件，前身是阿里的cobar
		2、分库分表：
		垂直分割（分库）：指按照业务将表进行分类，分布到不同的数据库上面，这样也就将数据或者说压力分担到不同的库上面
		水平分割（分表）：一个表格的数据按照行分割到多个节点上
		典型的分片规则：根据主键编号进行hash、求余
		3、mycat安装
			1.下载mycat并上传到linux：官方网站：http://www.mycat.org.cn
			2.解压mycat
				tar -zxvf Mycat-server-1.6-RELEASE-20161028204710-linux.tar.gz -C /usr/java
			3.启动和关闭mycat
				启动：./mycat start
				停止：./mycat stop
				重启：./mycat restart
				查看状态：./mycat status
			4.mycat重要概念：
				1、逻辑库（schema）：一个包含了所有数据库的逻辑上的数据库
				2、逻辑表（table）：一个包含了所有表的逻辑上的表
				3、数据主机（dataHost）：数据库软件安装到哪个服务器上
				4、数据节点（dataNode）：数据库软件中的 database
				5、分片规则（rule）：拆分规则
		4、分片规则
			1.auto-sharding-long 规则
				以 500 万为单位,实现分片规则：
				1-500 万保存在 db1 中, 500 万零 1 到 1000 万保存在 db2 中,1000 万零 1 到 1500 万保存在 db3 中
			2.crc32slot规则：在 CRUD 操作时,根据具体数据的 crc32 算法计算,数据应该保存在哪一个dataNode 中
				分片字段使用主键
				tableRule：一个表一个
				数据库节点数量
		5、配置mycat的分库分表和读写分离
			1、schema.xml作用：逻辑库、逻辑表、dataNode、分片规则
			2、rule.xml：分片规则
			3、server.xml：mycat的用户名、密码和权限
